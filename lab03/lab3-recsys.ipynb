{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 â€” recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"movieId\": 70286, \"userId\": 138493, \"timestamp\": 1258126944, \"rating\": 5.0}\r\n",
      "{\"movieId\": 71619, \"userId\": 138493, \"timestamp\": 1255811136, \"rating\": 2.5}\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /ix/ml-20m/ratings.txt | tail -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/ix/ml-20m/ratings.txt\").map(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4 Basic statistics :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ratings = data.map(lambda x: (x['userId'], x['rating']))\n",
    "users_counts = users_ratings.countByKey().items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_ratings = data.map(lambda x: (x['movieId'], x['rating']))\n",
    "movies_counts = movies_ratings.countByKey().items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAFVCAYAAABRmurcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa00d2be898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumulative_users = np.cumsum(sorted(list(users_counts)))\n",
    "cumulative_movies = np.cumsum(sorted(list(movies_counts)))\n",
    "\n",
    "fig, (axe1, axe2) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "axe1.plot(cumulative_users)\n",
    "axe1.set_title(\"Users\")\n",
    "axe1.set_xlabel('User')\n",
    "axe1.set_ylabel('Ratings')\n",
    "\n",
    "axe2.plot(cumulative_movies)\n",
    "axe2.set_title(\"Movies\")\n",
    "axe2.set_xlabel('User')\n",
    "axe2.set_ylabel('Ratings')\n",
    "\n",
    "axe2.loglog()\n",
    "axe1.loglog()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users have a lot of ratings as well as movies and users having little number of ratings. The distributions of the ratings isn't balanced uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5 Partitioning the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "personnal_ratings = list() ## add the personnal ranking somehow\n",
    "with open(\"my-ratings.txt\") as f :\n",
    "    for line in f:\n",
    "        personnal_ratings.append(json.loads(line.strip()))\n",
    "\n",
    "newData = data.union(sc.parallelize(personnal_ratings))\n",
    "\n",
    "training = newData.filter(lambda x: (x['timestamp'] % 10) > 1).map(lambda x: (x['userId'], x['movieId'], x['rating']))\n",
    "test = newData.filter(lambda x: (x['timestamp'] % 10) <= 1).map(lambda x: (x['userId'], x['movieId'], x['rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = training.map(lambda x: x[2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5255073364131335"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, 3.72)]\n"
     ]
    }
   ],
   "source": [
    "## find how to get all_user_bias and all_item_bias\n",
    "all_user_mean = training.map(lambda x: (x[0], x[2])).aggregateByKey((0,0), lambda a,b: (a[0] + b,a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda v: v[0]/v[1])\n",
    "all_user_bias = all_user_mean.map(lambda x: (x[0], x[1]-mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10160805230563459"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_user_bias = all_user_bias.values().mean()\n",
    "mean_user_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 235, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 409, in dump\n",
      "    self.save(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 751, in save_tuple\n",
      "    save(element)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 808, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 372, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\", line 525, in save_function_tuple\n",
      "    save(f_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/opt/anaconda3/lib/python3.6/pickle.py\", line 496, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 208, in __getnewargs__\n",
      "    \"It appears that you are attempting to broadcast an RDD or reference an RDD from an \"\n",
      "Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 or themodule is None):\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# save the rest of the func data needed by _fill_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m__getnewargs__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         raise Exception(\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;34m\"It appears that you are attempting to broadcast an RDD or reference an RDD from an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;34m\"action or transformation. RDD transformations and actions can only be invoked by the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5dd97adfb2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_item_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mall_user_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregateByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36maggregateByKey\u001b[0;34m(self, zeroValue, seqFunc, combFunc, numPartitions, partitionFunc)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         return self.combineByKey(\n\u001b[0;32m-> 1887\u001b[0;31m             lambda v: seqFunc(createZero(), v), seqFunc, combFunc, numPartitions, partitionFunc)\n\u001b[0m\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfoldByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumPartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitionFunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mportable_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcombineByKey\u001b[0;34m(self, createCombiner, mergeValue, mergeCombiners, numPartitions, partitionFunc)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m         \u001b[0mlocally_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombineLocally\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m         \u001b[0mshuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocally_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumPartitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_mergeCombiners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mpartitionBy\u001b[0;34m(self, numPartitions, partitionFunc)\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m             pairRDD = self.ctx._jvm.PairwiseRDD(\n\u001b[0;32m-> 1800\u001b[0;31m                 keyed._jrdd.rdd()).asJavaPairRDD()\n\u001b[0m\u001b[1;32m   1801\u001b[0m             jpartitioner = self.ctx._jvm.PythonPartitioner(numPartitions,\n\u001b[1;32m   1802\u001b[0m                                                            id(partitionFunc))\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2472\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2473\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2474\u001b[0m                                              self.preservesPartitioning)\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m   2407\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2389\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063."
     ]
    }
   ],
   "source": [
    "all_item_bias = training.map(lambda x: (x[1], x[2] - all_user_bias[x[0]] - mu)).aggregateByKey((0,0), lambda a,b: (a[0] + b,a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda v: v[0]/v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 27.0 failed 4 times, most recent failure: Lost task 1.3 in stage 27.0 (TID 186, iccluster057.iccluster.epfl.ch, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 350, in func\n    return f(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 1859, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/shuffle.py\", line 237, in mergeValues\n    for k, v in iterator:\n  File \"/usr/hdp/current/spark2-client/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-46-b929fb30501f>\", line 1, in <lambda>\nNameError: name 'user_biases' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1126)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1132)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:165)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 350, in func\n    return f(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 1859, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/shuffle.py\", line 237, in mergeValues\n    for k, v in iterator:\n  File \"/usr/hdp/current/spark2-client/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-46-b929fb30501f>\", line 1, in <lambda>\nNameError: name 'user_biases' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1126)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1132)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-27a11fe85f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_item_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_item_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmean_item_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \"\"\"\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mstats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mleft_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergeStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStatCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 27.0 failed 4 times, most recent failure: Lost task 1.3 in stage 27.0 (TID 186, iccluster057.iccluster.epfl.ch, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 350, in func\n    return f(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 1859, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/shuffle.py\", line 237, in mergeValues\n    for k, v in iterator:\n  File \"/usr/hdp/current/spark2-client/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-46-b929fb30501f>\", line 1, in <lambda>\nNameError: name 'user_biases' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1126)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1132)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:165)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 253, in main\n    process()\n  File \"/usr/hdp/current/spark2-client/python/pyspark/worker.py\", line 248, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 2440, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 350, in func\n    return f(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/rdd.py\", line 1859, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/shuffle.py\", line 237, in mergeValues\n    for k, v in iterator:\n  File \"/usr/hdp/current/spark2-client/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-46-b929fb30501f>\", line 1, in <lambda>\nNameError: name 'user_biases' is not defined\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:330)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:470)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:453)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:284)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1126)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1132)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "mean_item_bias = all_item_bias.values().mean()\n",
    "mean_item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_bias(userId):\n",
    "    if userId in all_user_bias.keys():\n",
    "        return all_user_bias[userId]\n",
    "    \n",
    "    return ## Use mean of biases\n",
    "\n",
    "def item_bias(movieId):\n",
    "    if movieId in all_item_bias.keys():\n",
    "        return all_item_bias[movieId]\n",
    "    \n",
    "    return ## Use mean of biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(user, movie):\n",
    "    return ((user, movie), mu + user_bias(user) + item_bias(movie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(rdd):\n",
    "    ranks_and_preds = test.map(lambda x: ((x[0], x[1]), x[2])).join(rdd)\n",
    "    err = ## Implement the error calculation\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower rank implies simpler model, thus a faster training. Higher rank increases the amount of parameters used in the learning process, thus the probability of overfitting increases with the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Choose the rank ? (Shall we use 10 ?)\n",
    "rank = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = 10e-4\n",
    "model = ALS.train(training, rank, lambda_=param)\n",
    "prediction = model.predictAll(\"SOME DATA HERE\").map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "\n",
    "error = error(prediction)\n",
    "print('Error with lambda=10^-4: ', error)\n",
    "\n",
    "param2 = 10.0\n",
    "model2 = ALS.train(training, rank, lambda_=param2)\n",
    "prediction2 = model.predictAll(\"SOME DATA HERE\").map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "\n",
    "error2 = error(prediction)\n",
    "print('Error with lambda=10.0: ', error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Find optimal lambda below\n",
    "optimal_lambda = VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ALS.train(\"DATA\", rank=10, lambda_=optimal_lambda)\n",
    "\n",
    "movies = sc.textFile(\"/ix/ml-20m/movies.txt\").map(json.loads)\n",
    "ids_to_title = movies.map(itemgetter(\"movieId\", \"title\")).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Do the recommendation for both users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model = ALS.train(training, rank=2, lambda_=optimal_lambda)\n",
    "selected_movies = sorted(pickle.load(open('selected-movies.pickle', 'rb'), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "â€¢ Create an interactive plot that embeds the movies along the 2 directions defined by the\n",
    "factorization.\n",
    "â€¢ Describe what you observe. Can you give a name to the dimensions? Do you recognize\n",
    "cluster of movies that are alike?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
