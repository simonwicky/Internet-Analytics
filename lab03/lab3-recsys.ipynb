{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 — recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /ix/ml-20m/ratings.txt | tail -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/ix/ml-20m/ratings.txt\").map(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4 Basic statistics :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ratings = data.map(lambda x: (x['userId'], x['rating']))\n",
    "users_counts = users_ratings.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings = data.map(lambda x: (x['movieId'], x['rating']))\n",
    "movies_counts = movies_ratings.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_users = np.cumsum(users_counts)\n",
    "cumulative_movies = np.cumsum(movies_counts)\n",
    "\n",
    "fig, (axe1, axe2) = plt.subplots(ncols=2)\n",
    "\n",
    "axe1.plot(cumulative_users)\n",
    "axe1.set_title(\"Users\")\n",
    "axe1.set_xlabel('User')\n",
    "axe1.set_ylabel('Ratings')\n",
    "\n",
    "axe2.plot(cumulative_movies)\n",
    "axe2.set_title(\"Movies\")\n",
    "axe2.set_xlabel('User')\n",
    "axe2.set_ylabel('Ratings')\n",
    "\n",
    "axe2.loglog()\n",
    "axe1.loglog()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users have a lot of ratings as well as movies and users with little number of ratings. The distributions of the ratings isn't balanced uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5 Partitioning the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personnal_ratings = sc.parallelize(\"something ?\") ## add the personnal ranking somehow\n",
    "\n",
    "newData = data.union(personnal_ratings)\n",
    "\n",
    "training = newData.filter(lambda x: (x['timestamp'] % 10) > 1)\n",
    "test = newData.filter(lambda x: (x['timestamp'] % 10) <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = training.map(lambda x: x[2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find how to get all_user_bias and all_item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_bias(userId):\n",
    "    if userId in all_user_bias.keys():\n",
    "        return all_user_bias[userId]\n",
    "    \n",
    "    return ## Use mean of biases\n",
    "\n",
    "def item_bias(movieId):\n",
    "    if movieId in all_item_bias.keys():\n",
    "        return all_item_bias[movieId]\n",
    "    \n",
    "    return ## Use mean of biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, movie):\n",
    "    return ((user, movie), mu + user_bias(user) + item_bias(movie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(rdd):\n",
    "    ranks_and_preds = test.map(lambda x: ((x[0], x[1]), x[2])).join(rdd)\n",
    "    err = ## Implement the error calculation\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower rank implies simpler model, thus a faster training. Higher rank increases the amount of parameters used in the learning process, thus the probability of overfitting increases with the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the rank ? (Shall we use 10 ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 10e-4\n",
    "model = ALS.train(training, rank, lambda_=param)\n",
    "prediction = model.predictAll(\"SOME DATA HERE\").map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "\n",
    "error = error(prediction)\n",
    "print('Error with lambda=10^-4: ', error)\n",
    "\n",
    "param2 = 10.0\n",
    "model2 = ALS.train(training, rank, lambda_=param2)\n",
    "prediction2 = model.predictAll(\"SOME DATA HERE\").map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "\n",
    "error2 = error(prediction)\n",
    "print('Error with lambda=10.0: ', error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find optimal lambda below\n",
    "optimal_lambda = VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(\"DATA\", rank=?, lambda_=optimal_lambda)\n",
    "\n",
    "movies = sc.textFile(\"/ix/ml-20m/movies.txt\").map(json.loads)\n",
    "ids_to_title = movies.map(itemgetter(\"movieId\", \"title\")).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the recommendation for both users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ALS.train(training, rank=2, lambda_=optimal_lambda)\n",
    "selected_movies = sorted(pickle.load(open('selected-movies.pickle', 'rb'), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "• Create an interactive plot that embeds the movies along the 2 directions defined by the\n",
    "factorization.\n",
    "• Describe what you observe. Can you give a name to the dimensions? Do you recognize\n",
    "cluster of movies that are alike?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
